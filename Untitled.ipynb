{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2734ac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import tensorflow\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "#from tensorflow.keras.utils import np_utils\n",
    "from tensorflow.keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa4efa6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 24, 3)\n"
     ]
    }
   ],
   "source": [
    "im = cv2.imread('./image_chips2/clipped_image_254.png')\n",
    "#im2 = Image.open('./image_chips/clipped_image_1.tif.png')\n",
    "\n",
    "\n",
    "print(im.shape)\n",
    "\n",
    "\n",
    "'''\n",
    "cv2.imshow('image', im)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "image_files = glob.glob('./image_chips2/*.png')\n",
    "#print(image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d3a07fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]], dtype=uint8)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create labeled dataset for y_train.\n",
    "y_train = np.array([np.random.randint(0,2)  for i in range(len(image_files))])\n",
    "y_train = y_train.astype('uint8')\n",
    "y_train = y_train.reshape(426,1)\n",
    "y_train\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3c1fbda0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 426)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train), len(image_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445e72c9",
   "metadata": {},
   "source": [
    "#### Now we'll look at a sample dataset to get the idea of how to format our own dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6fbfacd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0ff7e9af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6370f62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [9],\n",
       "       [9],\n",
       "       ...,\n",
       "       [9],\n",
       "       [1],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba82c890",
   "metadata": {},
   "source": [
    "#### now we'll convert our image dataset into a similar format as the sample image set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0e7c2078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 24, 24, 3)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image = []\n",
    "for i in image_files:\n",
    "    im = np.array(cv2.imread(i))\n",
    "    train_image.append(im)\n",
    "\n",
    "\n",
    "train_image = np.array(train_image)\n",
    "train_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "de3faed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.67843137, 0.70980392, 0.71764706],\n",
       "         [0.67843137, 0.70980392, 0.71764706],\n",
       "         [0.67843137, 0.70980392, 0.71764706],\n",
       "         ...,\n",
       "         [0.69019608, 0.71764706, 0.7254902 ],\n",
       "         [0.68235294, 0.71372549, 0.71764706],\n",
       "         [0.68235294, 0.71372549, 0.71764706]],\n",
       "\n",
       "        [[0.69411765, 0.72941176, 0.7372549 ],\n",
       "         [0.69411765, 0.72941176, 0.7372549 ],\n",
       "         [0.69411765, 0.72941176, 0.7372549 ],\n",
       "         ...,\n",
       "         [0.70196078, 0.72941176, 0.7372549 ],\n",
       "         [0.69411765, 0.7254902 , 0.72941176],\n",
       "         [0.69019608, 0.72156863, 0.7254902 ]],\n",
       "\n",
       "        [[0.71372549, 0.74901961, 0.75686275],\n",
       "         [0.71372549, 0.74901961, 0.75686275],\n",
       "         [0.70980392, 0.74901961, 0.76078431],\n",
       "         ...,\n",
       "         [0.71372549, 0.74117647, 0.74901961],\n",
       "         [0.70588235, 0.7372549 , 0.74117647],\n",
       "         [0.70196078, 0.73333333, 0.7372549 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.61568627, 0.71764706, 0.7372549 ],\n",
       "         [0.61568627, 0.72156863, 0.74509804],\n",
       "         [0.60784314, 0.71372549, 0.73333333],\n",
       "         ...,\n",
       "         [0.43529412, 0.54117647, 0.54509804],\n",
       "         [0.41568627, 0.52156863, 0.5254902 ],\n",
       "         [0.40392157, 0.50980392, 0.51372549]],\n",
       "\n",
       "        [[0.64313725, 0.75294118, 0.77647059],\n",
       "         [0.65098039, 0.76470588, 0.79215686],\n",
       "         [0.64313725, 0.75686275, 0.78039216],\n",
       "         ...,\n",
       "         [0.45882353, 0.57254902, 0.57647059],\n",
       "         [0.48235294, 0.59607843, 0.6       ],\n",
       "         [0.50980392, 0.62352941, 0.62745098]],\n",
       "\n",
       "        [[0.63137255, 0.74117647, 0.76470588],\n",
       "         [0.63921569, 0.75294118, 0.78039216],\n",
       "         [0.62745098, 0.74117647, 0.76470588],\n",
       "         ...,\n",
       "         [0.31372549, 0.42352941, 0.42745098],\n",
       "         [0.36470588, 0.4745098 , 0.47843137],\n",
       "         [0.41960784, 0.52941176, 0.53333333]]],\n",
       "\n",
       "\n",
       "       [[[0.27843137, 0.38431373, 0.32156863],\n",
       "         [0.30196078, 0.41568627, 0.35294118],\n",
       "         [0.3254902 , 0.43921569, 0.38039216],\n",
       "         ...,\n",
       "         [0.28235294, 0.40784314, 0.36470588],\n",
       "         [0.28235294, 0.4       , 0.35686275],\n",
       "         [0.27843137, 0.40392157, 0.35294118]],\n",
       "\n",
       "        [[0.25098039, 0.35686275, 0.31764706],\n",
       "         [0.25490196, 0.36470588, 0.3254902 ],\n",
       "         [0.26666667, 0.37647059, 0.34117647],\n",
       "         ...,\n",
       "         [0.28235294, 0.4       , 0.37254902],\n",
       "         [0.2745098 , 0.38823529, 0.36078431],\n",
       "         [0.27843137, 0.39607843, 0.36470588]],\n",
       "\n",
       "        [[0.32156863, 0.42745098, 0.40784314],\n",
       "         [0.29411765, 0.4       , 0.38431373],\n",
       "         [0.27058824, 0.37647059, 0.36470588],\n",
       "         ...,\n",
       "         [0.34901961, 0.45882353, 0.44313725],\n",
       "         [0.34509804, 0.45490196, 0.43921569],\n",
       "         [0.34509804, 0.45490196, 0.43921569]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.74901961, 0.78431373, 0.79215686],\n",
       "         [0.74901961, 0.78431373, 0.79215686],\n",
       "         [0.75294118, 0.78823529, 0.79607843],\n",
       "         ...,\n",
       "         [0.75686275, 0.79607843, 0.80392157],\n",
       "         [0.75686275, 0.79607843, 0.80392157],\n",
       "         [0.75686275, 0.8       , 0.80784314]],\n",
       "\n",
       "        [[0.7372549 , 0.77647059, 0.78431373],\n",
       "         [0.74117647, 0.78039216, 0.78823529],\n",
       "         [0.74509804, 0.78431373, 0.79215686],\n",
       "         ...,\n",
       "         [0.75686275, 0.8       , 0.80784314],\n",
       "         [0.75686275, 0.8       , 0.80784314],\n",
       "         [0.75294118, 0.8       , 0.80784314]],\n",
       "\n",
       "        [[0.73333333, 0.77647059, 0.78431373],\n",
       "         [0.7372549 , 0.78039216, 0.78823529],\n",
       "         [0.74117647, 0.78431373, 0.79215686],\n",
       "         ...,\n",
       "         [0.75294118, 0.8       , 0.81176471],\n",
       "         [0.75294118, 0.8       , 0.81176471],\n",
       "         [0.74901961, 0.8       , 0.81176471]]],\n",
       "\n",
       "\n",
       "       [[[0.5254902 , 0.68235294, 0.76078431],\n",
       "         [0.54117647, 0.68627451, 0.76862745],\n",
       "         [0.51372549, 0.64705882, 0.72941176],\n",
       "         ...,\n",
       "         [0.49803922, 0.65490196, 0.7372549 ],\n",
       "         [0.49019608, 0.64705882, 0.7254902 ],\n",
       "         [0.48627451, 0.64313725, 0.72156863]],\n",
       "\n",
       "        [[0.52156863, 0.68627451, 0.76078431],\n",
       "         [0.52156863, 0.67843137, 0.75686275],\n",
       "         [0.58039216, 0.72941176, 0.80784314],\n",
       "         ...,\n",
       "         [0.50980392, 0.67058824, 0.75294118],\n",
       "         [0.50980392, 0.67058824, 0.74901961],\n",
       "         [0.50980392, 0.67058824, 0.74901961]],\n",
       "\n",
       "        [[0.52156863, 0.69019608, 0.76470588],\n",
       "         [0.50588235, 0.67058824, 0.74901961],\n",
       "         [0.54509804, 0.70588235, 0.78431373],\n",
       "         ...,\n",
       "         [0.5254902 , 0.69019608, 0.77254902],\n",
       "         [0.52941176, 0.69411765, 0.77647059],\n",
       "         [0.53333333, 0.69803922, 0.78039216]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.12156863, 0.10196078, 0.12156863],\n",
       "         [0.12156863, 0.09411765, 0.10980392],\n",
       "         [0.14117647, 0.10588235, 0.11372549],\n",
       "         ...,\n",
       "         [0.59607843, 0.7372549 , 0.80392157],\n",
       "         [0.57254902, 0.71764706, 0.79215686],\n",
       "         [0.54901961, 0.69411765, 0.78039216]],\n",
       "\n",
       "        [[0.12156863, 0.09411765, 0.10196078],\n",
       "         [0.12156863, 0.08235294, 0.08627451],\n",
       "         [0.13333333, 0.08235294, 0.07843137],\n",
       "         ...,\n",
       "         [0.59607843, 0.72941176, 0.8       ],\n",
       "         [0.56862745, 0.70588235, 0.78431373],\n",
       "         [0.54117647, 0.67843137, 0.76862745]],\n",
       "\n",
       "        [[0.10980392, 0.09411765, 0.10196078],\n",
       "         [0.09803922, 0.07058824, 0.07843137],\n",
       "         [0.11764706, 0.07843137, 0.07843137],\n",
       "         ...,\n",
       "         [0.57254902, 0.73333333, 0.80784314],\n",
       "         [0.54117647, 0.70588235, 0.78823529],\n",
       "         [0.50980392, 0.67843137, 0.77254902]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.45098039, 0.50588235, 0.50980392],\n",
       "         [0.43529412, 0.48627451, 0.49019608],\n",
       "         [0.45490196, 0.50588235, 0.50588235],\n",
       "         ...,\n",
       "         [0.43921569, 0.51372549, 0.51764706],\n",
       "         [0.43137255, 0.51372549, 0.51764706],\n",
       "         [0.43529412, 0.52156863, 0.5254902 ]],\n",
       "\n",
       "        [[0.42745098, 0.4745098 , 0.47843137],\n",
       "         [0.42352941, 0.46666667, 0.47058824],\n",
       "         [0.44705882, 0.49019608, 0.49019608],\n",
       "         ...,\n",
       "         [0.43921569, 0.50980392, 0.51372549],\n",
       "         [0.43137255, 0.50980392, 0.51372549],\n",
       "         [0.42745098, 0.50980392, 0.51372549]],\n",
       "\n",
       "        [[0.40784314, 0.44705882, 0.45098039],\n",
       "         [0.42745098, 0.4627451 , 0.46666667],\n",
       "         [0.43529412, 0.47058824, 0.47058824],\n",
       "         ...,\n",
       "         [0.43529412, 0.50196078, 0.50588235],\n",
       "         [0.43137255, 0.50588235, 0.50980392],\n",
       "         [0.42352941, 0.50196078, 0.50588235]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.67058824, 0.76470588, 0.79215686],\n",
       "         [0.70588235, 0.79607843, 0.82352941],\n",
       "         [0.68627451, 0.77647059, 0.8       ],\n",
       "         ...,\n",
       "         [0.67058824, 0.74509804, 0.74117647],\n",
       "         [0.67058824, 0.74509804, 0.74117647],\n",
       "         [0.6745098 , 0.74509804, 0.74117647]],\n",
       "\n",
       "        [[0.67058824, 0.76078431, 0.78431373],\n",
       "         [0.69803922, 0.78823529, 0.81176471],\n",
       "         [0.63529412, 0.7254902 , 0.74509804],\n",
       "         ...,\n",
       "         [0.66666667, 0.74117647, 0.74117647],\n",
       "         [0.66666667, 0.74117647, 0.74117647],\n",
       "         [0.67058824, 0.74509804, 0.74509804]],\n",
       "\n",
       "        [[0.6745098 , 0.76078431, 0.78039216],\n",
       "         [0.69019608, 0.77647059, 0.79607843],\n",
       "         [0.58823529, 0.6745098 , 0.69411765],\n",
       "         ...,\n",
       "         [0.66666667, 0.74117647, 0.74509804],\n",
       "         [0.66666667, 0.74117647, 0.74509804],\n",
       "         [0.67058824, 0.74509804, 0.74901961]]],\n",
       "\n",
       "\n",
       "       [[[0.62352941, 0.75686275, 0.76078431],\n",
       "         [0.63529412, 0.76470588, 0.77254902],\n",
       "         [0.56862745, 0.69411765, 0.70196078],\n",
       "         ...,\n",
       "         [0.74117647, 0.83529412, 0.84313725],\n",
       "         [0.7254902 , 0.82745098, 0.83529412],\n",
       "         [0.72156863, 0.82745098, 0.83529412]],\n",
       "\n",
       "        [[0.58039216, 0.71764706, 0.71372549],\n",
       "         [0.60392157, 0.7372549 , 0.7372549 ],\n",
       "         [0.55686275, 0.68627451, 0.68627451],\n",
       "         ...,\n",
       "         [0.7372549 , 0.83529412, 0.83921569],\n",
       "         [0.72941176, 0.83137255, 0.83529412],\n",
       "         [0.7254902 , 0.83137255, 0.83921569]],\n",
       "\n",
       "        [[0.54509804, 0.68235294, 0.67058824],\n",
       "         [0.57647059, 0.70980392, 0.70196078],\n",
       "         [0.54901961, 0.67843137, 0.6745098 ],\n",
       "         ...,\n",
       "         [0.7372549 , 0.83529412, 0.83921569],\n",
       "         [0.73333333, 0.83529412, 0.83921569],\n",
       "         [0.72941176, 0.83529412, 0.84313725]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.70980392, 0.72156863, 0.6627451 ],\n",
       "         [0.7372549 , 0.74509804, 0.68235294],\n",
       "         [0.70980392, 0.71372549, 0.64705882],\n",
       "         ...,\n",
       "         [0.30196078, 0.23921569, 0.16078431],\n",
       "         [0.38823529, 0.31764706, 0.23529412],\n",
       "         [0.48235294, 0.4       , 0.31372549]],\n",
       "\n",
       "        [[0.69803922, 0.70980392, 0.65098039],\n",
       "         [0.71764706, 0.7254902 , 0.6627451 ],\n",
       "         [0.7372549 , 0.74117647, 0.6745098 ],\n",
       "         ...,\n",
       "         [0.25882353, 0.21568627, 0.14509804],\n",
       "         [0.28627451, 0.23921569, 0.16470588],\n",
       "         [0.32156863, 0.26666667, 0.18823529]],\n",
       "\n",
       "        [[0.68627451, 0.70196078, 0.64313725],\n",
       "         [0.70196078, 0.71372549, 0.65098039],\n",
       "         [0.71372549, 0.72156863, 0.65490196],\n",
       "         ...,\n",
       "         [0.22745098, 0.20784314, 0.14117647],\n",
       "         [0.23137255, 0.20784314, 0.1372549 ],\n",
       "         [0.23921569, 0.21176471, 0.14117647]]],\n",
       "\n",
       "\n",
       "       [[[0.19607843, 0.25882353, 0.25882353],\n",
       "         [0.23137255, 0.29411765, 0.29019608],\n",
       "         [0.45490196, 0.51372549, 0.50980392],\n",
       "         ...,\n",
       "         [0.34509804, 0.39215686, 0.41568627],\n",
       "         [0.3372549 , 0.38431373, 0.40392157],\n",
       "         [0.34901961, 0.39215686, 0.40392157]],\n",
       "\n",
       "        [[0.30588235, 0.35686275, 0.35294118],\n",
       "         [0.26666667, 0.32156863, 0.31764706],\n",
       "         [0.41960784, 0.47843137, 0.4745098 ],\n",
       "         ...,\n",
       "         [0.35686275, 0.41176471, 0.42745098],\n",
       "         [0.34117647, 0.39215686, 0.40392157],\n",
       "         [0.3372549 , 0.38431373, 0.38823529]],\n",
       "\n",
       "        [[0.50980392, 0.54901961, 0.54117647],\n",
       "         [0.32156863, 0.37254902, 0.36470588],\n",
       "         [0.45882353, 0.51764706, 0.50980392],\n",
       "         ...,\n",
       "         [0.36078431, 0.42352941, 0.43137255],\n",
       "         [0.34509804, 0.4       , 0.40392157],\n",
       "         [0.32156863, 0.37254902, 0.36470588]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.8745098 , 0.89019608, 0.84705882],\n",
       "         [0.85882353, 0.8745098 , 0.83529412],\n",
       "         [0.84313725, 0.85882353, 0.82352941],\n",
       "         ...,\n",
       "         [0.31372549, 0.30588235, 0.30588235],\n",
       "         [0.3372549 , 0.30980392, 0.31372549],\n",
       "         [0.32941176, 0.32156863, 0.3254902 ]],\n",
       "\n",
       "        [[0.83137255, 0.85490196, 0.81568627],\n",
       "         [0.82352941, 0.84705882, 0.81176471],\n",
       "         [0.81568627, 0.83921569, 0.80784314],\n",
       "         ...,\n",
       "         [0.74509804, 0.71372549, 0.70980392],\n",
       "         [0.70196078, 0.65098039, 0.65098039],\n",
       "         [0.58431373, 0.56078431, 0.56470588]],\n",
       "\n",
       "        [[0.79607843, 0.82352941, 0.78823529],\n",
       "         [0.79607843, 0.82352941, 0.79215686],\n",
       "         [0.79607843, 0.82352941, 0.79607843],\n",
       "         ...,\n",
       "         [0.9254902 , 0.86666667, 0.8627451 ],\n",
       "         [0.87843137, 0.80392157, 0.80392157],\n",
       "         [0.74509804, 0.70196078, 0.70588235]]]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_image / 255.\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fb63d230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((426, 24, 24, 3), (426, 1))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1c9c6b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (50000, 1))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2675c097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "34d83a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(24, (3, 3), activation='relu', input_shape=(24, 24, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(48, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(48, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a427c200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 22, 22, 24)        672       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 11, 11, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 9, 9, 48)          10416     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 4, 4, 48)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 2, 2, 48)          20784     \n",
      "=================================================================\n",
      "Total params: 31,872\n",
      "Trainable params: 31,872\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dc8642b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(48, activation='relu'))\n",
    "model.add(layers.Dense(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "baf98f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2999813f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.7018 - accuracy: 0.4881\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6910 - accuracy: 0.5470\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6947 - accuracy: 0.5110\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5152\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6904 - accuracy: 0.5016\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6905 - accuracy: 0.5280\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6847 - accuracy: 0.5915\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6823 - accuracy: 0.5820\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6877 - accuracy: 0.5446\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.6138\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6673 - accuracy: 0.6045\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6519 - accuracy: 0.6380\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6493 - accuracy: 0.6106\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6539 - accuracy: 0.5922\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6371 - accuracy: 0.6495\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6315 - accuracy: 0.6399\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6062 - accuracy: 0.6510\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5938 - accuracy: 0.6952\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5977 - accuracy: 0.6716\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5341 - accuracy: 0.7586\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5437 - accuracy: 0.7058\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.7168\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5251 - accuracy: 0.7361\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.7982\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.8254\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.7962\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4093 - accuracy: 0.8347\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.3828 - accuracy: 0.8433\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.3431 - accuracy: 0.8608\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.3302 - accuracy: 0.8619\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.2852 - accuracy: 0.8809\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.2392 - accuracy: 0.9276\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.2245 - accuracy: 0.9261\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.2103 - accuracy: 0.9296\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1733 - accuracy: 0.9573\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1326 - accuracy: 0.9561\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1315 - accuracy: 0.9731\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1172 - accuracy: 0.9785\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9589\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1438 - accuracy: 0.9478\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1808 - accuracy: 0.9272\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1218 - accuracy: 0.9676\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1138 - accuracy: 0.9558\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0997 - accuracy: 0.9645\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0902 - accuracy: 0.9895\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0393 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0299 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0223 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x174d60e52e0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size= 32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fe735c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.6995465159416199,\n",
       "  0.6935949325561523,\n",
       "  0.6963809132575989,\n",
       "  0.6941283941268921,\n",
       "  0.6909209489822388,\n",
       "  0.6891574263572693,\n",
       "  0.6853758096694946,\n",
       "  0.6840184330940247,\n",
       "  0.6827278733253479,\n",
       "  0.6740249395370483,\n",
       "  0.6655118465423584,\n",
       "  0.6562219262123108,\n",
       "  0.6617651581764221,\n",
       "  0.6431182026863098,\n",
       "  0.6372345685958862,\n",
       "  0.625067412853241,\n",
       "  0.5999442338943481,\n",
       "  0.594302237033844,\n",
       "  0.5910290479660034,\n",
       "  0.5547003149986267,\n",
       "  0.5430309772491455,\n",
       "  0.53497713804245,\n",
       "  0.5235233306884766,\n",
       "  0.4811823070049286,\n",
       "  0.4534958004951477,\n",
       "  0.46889081597328186,\n",
       "  0.40070924162864685,\n",
       "  0.38340699672698975,\n",
       "  0.33373111486434937,\n",
       "  0.331525593996048,\n",
       "  0.2945222854614258,\n",
       "  0.24440526962280273,\n",
       "  0.2247897982597351,\n",
       "  0.2068415731191635,\n",
       "  0.17777712643146515,\n",
       "  0.14802545309066772,\n",
       "  0.12509486079216003,\n",
       "  0.11657904088497162,\n",
       "  0.14820007979869843,\n",
       "  0.1770002841949463,\n",
       "  0.18431195616722107,\n",
       "  0.1335686445236206,\n",
       "  0.11247950792312622,\n",
       "  0.09763606637716293,\n",
       "  0.07659358531236649,\n",
       "  0.04202521964907646,\n",
       "  0.030061041936278343,\n",
       "  0.02332882769405842,\n",
       "  0.02225596085190773,\n",
       "  0.0175752155482769,\n",
       "  0.015311244875192642,\n",
       "  0.013077354058623314,\n",
       "  0.011739751324057579,\n",
       "  0.010334063321352005,\n",
       "  0.00943257100880146,\n",
       "  0.008978516794741154,\n",
       "  0.008113672025501728,\n",
       "  0.00722614536061883,\n",
       "  0.0068615153431892395,\n",
       "  0.006332536228001118,\n",
       "  0.005810197908431292,\n",
       "  0.00550317857414484,\n",
       "  0.005116836633533239,\n",
       "  0.004786443430930376,\n",
       "  0.004482564050704241,\n",
       "  0.004248190205544233,\n",
       "  0.003989724442362785,\n",
       "  0.003813842311501503,\n",
       "  0.0036239204928278923,\n",
       "  0.003458254039287567,\n",
       "  0.00322630419395864,\n",
       "  0.0030568416696041822,\n",
       "  0.0029162887949496508,\n",
       "  0.002763468539342284,\n",
       "  0.002690462628379464,\n",
       "  0.0025315750390291214,\n",
       "  0.0024851656053215265,\n",
       "  0.0023238472640514374,\n",
       "  0.0022366633638739586,\n",
       "  0.0021439010743051767,\n",
       "  0.002051434712484479,\n",
       "  0.0019690105691552162,\n",
       "  0.00191503984387964,\n",
       "  0.0018193534342572093,\n",
       "  0.0017565262969583273,\n",
       "  0.0016859614988788962,\n",
       "  0.0016368260839954019,\n",
       "  0.0015836355742067099,\n",
       "  0.0015230519929900765,\n",
       "  0.0014738066820427775,\n",
       "  0.0014283049385994673,\n",
       "  0.0013878190657123923,\n",
       "  0.001331218983978033,\n",
       "  0.0012793901842087507,\n",
       "  0.0012387109454721212,\n",
       "  0.001211474183946848,\n",
       "  0.0011686431244015694,\n",
       "  0.001130516524426639,\n",
       "  0.0010845299111679196,\n",
       "  0.001058050780557096],\n",
       " 'accuracy': [0.4976525902748108,\n",
       "  0.5305164456367493,\n",
       "  0.5046948194503784,\n",
       "  0.47887325286865234,\n",
       "  0.49295774102211,\n",
       "  0.5492957830429077,\n",
       "  0.565727710723877,\n",
       "  0.565727710723877,\n",
       "  0.579812228679657,\n",
       "  0.5985915660858154,\n",
       "  0.6009389758110046,\n",
       "  0.6267605423927307,\n",
       "  0.5985915660858154,\n",
       "  0.6338028311729431,\n",
       "  0.6361502408981323,\n",
       "  0.6384976506233215,\n",
       "  0.6830986142158508,\n",
       "  0.6924882531166077,\n",
       "  0.6784037351608276,\n",
       "  0.7323943376541138,\n",
       "  0.7089201807975769,\n",
       "  0.7253521084785461,\n",
       "  0.7441314458847046,\n",
       "  0.7723004817962646,\n",
       "  0.8169013857841492,\n",
       "  0.7793427109718323,\n",
       "  0.84272301197052,\n",
       "  0.8333333134651184,\n",
       "  0.8685445785522461,\n",
       "  0.8638497591018677,\n",
       "  0.8779342770576477,\n",
       "  0.9272300601005554,\n",
       "  0.9295774698257446,\n",
       "  0.9319248795509338,\n",
       "  0.9460093975067139,\n",
       "  0.9577465057373047,\n",
       "  0.9741784334182739,\n",
       "  0.9788732528686523,\n",
       "  0.9507042169570923,\n",
       "  0.934272289276123,\n",
       "  0.9295774698257446,\n",
       "  0.9577465057373047,\n",
       "  0.9553990364074707,\n",
       "  0.9718309640884399,\n",
       "  0.9929577708244324,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0]}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4a8ff65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dfe14b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 24, 24, 3)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_train[0]\n",
    "X_test = X_test.reshape(1,24,24,3)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f3c1c822",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "eee19fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "69d66a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.4376407,  3.9843175]], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0f0bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda29202",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "'''train_image = np.expand_dims(train_image, axis=0)\n",
    "print(train_image.shape)'''\n",
    "\n",
    "\n",
    "'''\n",
    "# building a linear stack of layers with the sequential model\n",
    "model = Sequential()\n",
    "# convolutional layer\n",
    "model.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(24,24,1)))\n",
    "model.add(MaxPool2D(pool_size=(1,1)))\n",
    "# flatten output of conv\n",
    "model.add(Flatten())\n",
    "# hidden layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "# output layer\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "# compiling the sequential model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "# training the model for 10 epochs\n",
    "model.fit(train_image, y_train, epochs=100)\n",
    "\n",
    "'''\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
